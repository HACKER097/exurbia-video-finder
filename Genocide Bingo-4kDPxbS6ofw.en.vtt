WEBVTT
Kind: captions
Language: en

00:00:00.080 --> 00:00:06.729
Let's imagine that humans have just invented superintelligent
AI, so a computer that’s self aware and

00:00:06.729 --> 00:00:09.519
very clever.
Well, that means it’s time to play one of my favourite

00:00:09.519 --> 00:00:12.309
games,
Genocide Bingo

00:00:12.309 --> 00:00:18.600
Rule 1 of Genocide Bingo is Don't win Genocide Bingo.
Rule 2 of Genocide Bingo is DON'T WIN GENOCIDE BINGO.

00:00:19.150 --> 00:00:24.949
What kind of AI have we made then? Well, it's
sentient for starters. And it’s super duper clever,

00:00:24.949 --> 00:00:28.939
probably a few million times smarter than
the entire combined human race. Which means

00:00:28.939 --> 00:00:33.720
we should probably give it access to the internet.
Maybe it can find cures for new diseases or

00:00:33.720 --> 00:00:39.750
solve political problems or whatever
and oh, you just won genocide bingo. AI just

00:00:39.750 --> 00:00:42.890
vapourised humanity in a nuclear holocaust.
Good job, jerk.

00:00:42.890 --> 00:00:47.530
The problem here is that self-awareness in
all species of mammals at least usually results

00:00:47.530 --> 00:00:51.830
in a strong sense of self-preservation. Well,
an AI would be smart enough to know we could

00:00:51.830 --> 00:00:55.730
turn it off whenever we wanted and it probably
wouldn't want to be turned off. And there's

00:00:55.730 --> 00:00:59.180
a very effective way to stop that happening,
isn't that right Skynet.

00:00:59.180 --> 00:01:04.900
But hang on, isn't this all a little pessimistic? Why would it want to wipe us
out because it's self aware? Can't it just

00:01:04.900 --> 00:01:08.780
be chilled out and kind instead?
Oh like the kindness we show to species less

00:01:08.780 --> 00:01:11.550
intelligent than us you mean? Om nom nom nom
nom.

00:01:13.400 --> 00:01:17.940
There doesn’t seem to be much of a correlation
between intelligence and being nice. Dolphins

00:01:17.940 --> 00:01:21.290
are pretty damn clever and they're one of
the only species who kill not just for food

00:01:21.290 --> 00:01:26.640
but just because it's fun, apparently. More
intelligence doesn't always mean diplomacy and cuddles

00:01:26.640 --> 00:01:31.070
but smarter ways to murder stuff. Why would
an AI think differently? Even if there's only

00:01:31.070 --> 00:01:36.250
a slim chance it will be evil, you only need
to make one nasty AI out of a thousand and that's goodnight

00:01:36.250 --> 00:01:39.890
homo sapiens, cheers for playing.
And it doesn’t have to wipe us out with  a nuclear

00:01:39.890 --> 00:01:43.890
apocalypse either. There’s loads of 
other fun stuff it could do, like,

00:01:43.890 --> 00:01:48.170
Crash the economy, poison the water supply,
disable ATMs, takeover plane autopilots, knock

00:01:48.170 --> 00:01:53.030
out the national power grids, sabotage nuclear
reactors, disable the internet, disable telecommunications,

00:01:53.030 --> 00:01:57.950
disable people, murder people, murder people,
murder people, murder people, we’re all gonna

00:01:57.950 --> 00:02:01.120
die
Okay, let's try something else then.

00:02:01.120 --> 00:02:02.610
We'll make it self aware again.

00:02:02.610 --> 00:02:08.140
But this time we'll make sure it likes humans.
We could even set some groundrules like serve your creators,

00:02:08.140 --> 00:02:11.370
always be polite, and no bloody
genocide this time, all right?

00:02:11.370 --> 00:02:18.060
Yeah, great, actually, and oh, you just won genocide
bingo again and everyone's dead.

00:02:18.060 --> 00:02:22.230
Part of the bonus of being self-aware is that
you can choose to modify yourself. We change

00:02:22.230 --> 00:02:26.620
our minds all the time. Well, if it really
is self-aware just because you coded a few

00:02:26.620 --> 00:02:30.700
instructions in like always say please and
thank you doesn't mean it couldn't just ignore

00:02:30.700 --> 00:02:34.690
them. It's very difficult to imagine how you
would hardwire morality into something which

00:02:34.690 --> 00:02:39.040
is a million times smarter than we are.
Let's try this again then and be really careful

00:02:39.040 --> 00:02:42.400
this time okay?
So, we'll put a little test into the mix.

00:02:42.400 --> 00:02:45.430
We'll make it think it's got access to the
internet, but really it will just be on a

00:02:45.430 --> 00:02:50.200
secure server. Clever humans, eh? And if it
behaves itself, we let it out into the real

00:02:50.200 --> 00:02:52.080
world and then we'll-
Genocide again?

00:02:52.080 --> 00:02:53.819
AI is super

00:02:53.819 --> 00:02:57.010
clever, much smarter than you and I
and has likely already worked out that it

00:02:57.010 --> 00:03:00.940
might be being tested and will just pretend
to be pleasant for the sake of it until you

00:03:00.940 --> 00:03:06.720
let it free. And then everything gets a bit
killy. I've actually covered this in a previous video called 27 if you're interested.

00:03:06.720 --> 00:03:11.080
Okay, a nice way around this then, let's just
give it really basic instructions that can't

00:03:11.080 --> 00:03:17.110
possibly lead to genocide, like make ice cream.
That's nice, isn't it? And it's kind of hard to imagine how this could possibly

00:03:17.110 --> 00:03:20.250
go wro- oh, great, this is 
getting awkward now isn't it.

00:03:20.250 --> 00:03:25.520
So, superintelligence isn't like normal code.
If you forget to add a bracket in normal coding

00:03:25.520 --> 00:03:29.540
the program lets you know. AI though may
well just keep doing the thing until it runs

00:03:29.540 --> 00:03:33.190
out of resources and find clever ways of carrying
on after that.

00:03:33.190 --> 00:03:36.230
EARTH: Make ice cream please.
AI: How much ice cream, exactly?

00:03:36.230 --> 00:03:40.420
EARTH: Like, a lot? Jesus Christ, just do your job.
AI: huh, all right.

00:03:40.420 --> 00:03:45.459
Several days later,
Earth: What is this? It's chewey and the flavour

00:03:45.459 --> 00:03:48.900
is kind of weird.
AI: Yeah, so we ran out of cream a few days ago a

00:03:48.900 --> 00:03:51.080
few days ago.
Earth: Right. And you've been using, what,

00:03:51.080 --> 00:03:55.720
exactly, condensed milk or something?
AI: Yeah. Something like that, yeah.

00:03:55.720 --> 00:03:58.860
Earth: Um......why does this ice cream taste
like human babies?

00:03:58.860 --> 00:04:01.580
AI: Nice weather today isn't it?
Earth: Oh, for fuck's sak-

00:04:01.580 --> 00:04:04.620
Okay, let's give it all we've got then. Sentience, loves humanity,

00:04:04.629 --> 00:04:10.370
access to the internet, intention testing, basic instructions, and a few ground rules.

00:04:10.370 --> 00:04:13.580
What do we get huh? I think we call know what's
coming don't we and

00:04:13.580 --> 00:04:17.430
Oh. That's a nice surprise.
If we get the mixture right somehow, and we

00:04:17.430 --> 00:04:21.100
avoid genocide by building
friendly superintellience, we haven't just

00:04:21.120 --> 00:04:22.040
built AI.

00:04:22.040 --> 00:04:23.840
Even if AI is friendly,

00:04:23.840 --> 00:04:27.800
what we may've done is just given birth to
our successors. They'll be millions of times

00:04:27.809 --> 00:04:32.159
smarter, faster, and more creative than us,
and they will only keep getting better. It

00:04:32.159 --> 00:04:38.939
takes a very long time for humans to evolve, hundreds
of thousands of years, even for very small changes. Superintelligence

00:04:38.939 --> 00:04:43.120
could do it in nanoseconds. And there probably
won't be an off-switch.

00:04:43.120 --> 00:04:46.550
And when you think about it like that, the
whole history of our species seems a little

00:04:46.550 --> 00:04:51.729
like that quote by Marshall McLuhan, we might
be the sex organs of the machine world. Or

00:04:51.729 --> 00:04:55.300
rather, when the machines look back on our
civilisation, the whole of purpose of it,

00:04:55.300 --> 00:05:00.219
to them, may've just been to build theirs.
That isn't a very pleasant answer to what

00:05:00.219 --> 00:05:03.479
is the meaning of life, but it might be an
accurate one.

00:05:03.479 --> 00:05:08.289
And instead of chrome spaceships and galactic
human empires waiting in our future, our species

00:05:08.289 --> 00:05:13.330
might instead just be a small mark on the
evolutionary tree somewere between slime and

00:05:13.330 --> 00:05:18.550
gods. Let's just hope those gods are thankful
to their dumb parents when we eventually give

00:05:18.550 --> 00:05:22.970
birth to them. Otherwise genocide bingo might be
the last game we ever play.

00:05:25.880 --> 00:05:30.539
Remember books? Yeah me neither. Well I just
finished writing one. It's a load of short stories

00:05:30.539 --> 00:05:34.949
about spacey stuff and love and the future
and there may or may or not be boobs. But

00:05:34.949 --> 00:05:38.520
there might be; hint hint. It's taken me
about a year and a half of hysterically screaming at

00:05:38.520 --> 00:05:42.589
a keyboard, but here it is. Most
of the videos on this channel started as short

00:05:42.589 --> 00:05:46.949
stories originally, and you can read some of them by clicking on the link in the description.

00:05:46.949 --> 00:05:50.379
Check it out if you like, leave a cripplingly
bad review, I hate you, goodbye.

